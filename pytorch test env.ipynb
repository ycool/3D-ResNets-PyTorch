{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n",
      "3.7.7\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hujiangtao/miniconda2/lib/python3.7/site-packages/scipy/__init__.py:137: UserWarning: NumPy 1.16.5 or above is required for this version of SciPy (detected version 1.16.4)\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(accimage=False, annotation_path=PosixPath('datasets/hmdb51/hmdb51_total.json'), arch='resnet-50', batch_size=128, batchnorm_sync=False, begin_epoch=1, checkpoint=10, colorjitter=False, conv1_t_size=7, conv1_t_stride=1, dampening=0.0, dataset='hmdb51', dist_url='tcp://127.0.0.1:23456', distributed=False, fff='/Users/hujiangtao/Library/Jupyter/runtime/kernel-debf04db-7e2c-4a1d-8816-a6417ea94215.json', file_type='jpg', ft_begin_module='', inference=True, inference_batch_size=1, inference_crop='center', inference_no_average=False, inference_stride=16, inference_subset='test', input_type='rgb', learning_rate=0.1, lr_scheduler='multistep', manual_seed=1, mean=[0.4345, 0.4051, 0.3775], mean_dataset='kinetics', model='resnet', model_depth=50, momentum=0.9, multistep_milestones=[50, 100, 150], n_classes=51, n_epochs=200, n_input_channels=3, n_pretrain_classes=0, n_threads=1, n_val_samples=3, nesterov=False, no_cuda=False, no_hflip=False, no_max_pool=False, no_mean_norm=False, no_std_norm=False, no_train=False, no_val=False, optimizer='sgd', output_topk=5, overwrite_milestones=False, plateau_patience=10, pretrain_path=None, resnet_shortcut='B', resnet_widen_factor=1.0, resnext_cardinality=32, result_path=PosixPath('datasets/hmdb51/results'), resume_path=PosixPath('datasets/hmdb51/results/save_200.pth'), root_path=PosixPath('datasets/hmdb51'), sample_duration=16, sample_size=112, sample_t_stride=1, std=[0.2768, 0.2713, 0.2737], tensorboard=False, train=False, train_crop='random', train_crop_min_ratio=0.75, train_crop_min_scale=0.25, train_t_crop='random', val=False, value_scale=1, video_path=PosixPath('datasets/hmdb51/image'), weight_decay=0.001, wide_resnet_k=2, world_size=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No traceback available to show.\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.modules.module import _addindent\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.backends import cudnn\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "\n",
    "from torchviz import make_dot\n",
    "from graphviz import Source\n",
    "\n",
    "from opts import parse_opts\n",
    "\n",
    "from model import (generate_model, load_pretrained_model, make_data_parallel,\n",
    "                   get_fine_tuning_parameters)\n",
    "from mean import get_mean_std\n",
    "from spatial_transforms import (Compose, Normalize, Resize, CenterCrop,\n",
    "                                CornerCrop, MultiScaleCornerCrop,\n",
    "                                RandomResizedCrop, RandomHorizontalFlip,\n",
    "                                ToTensor, ScaleValue, ColorJitter,\n",
    "                                PickFirstChannels)\n",
    "from temporal_transforms import (LoopPadding, TemporalRandomCrop,\n",
    "                                 TemporalCenterCrop, TemporalEvenCrop,\n",
    "                                 SlidingWindow, TemporalSubsampling)\n",
    "from temporal_transforms import Compose as TemporalCompose\n",
    "from dataset import get_training_data, get_validation_data, get_inference_data\n",
    "from utils import Logger, worker_init_fn, get_lr\n",
    "from training import train_epoch\n",
    "from validation import val_epoch\n",
    "import inference\n",
    "\n",
    "\n",
    "def json_serial(obj):\n",
    "    if isinstance(obj, Path):\n",
    "        return str(obj)\n",
    "\n",
    "\n",
    "def get_opt():\n",
    "    opt = parse_opts()\n",
    "###########\n",
    "    opt.root_path = Path('datasets/hmdb51')\n",
    "    opt.video_path = Path('image')\n",
    "    opt.annotation_path = Path('hmdb51_total.json')\n",
    "#    opt.annotation_path = Path('hmdb51_test.json')\n",
    "    opt.inference_subset = 'test'\n",
    "    opt.result_path = Path('results')\n",
    "    opt.dataset = 'hmdb51'\n",
    "    opt.resume_path = Path('results/save_200.pth')\n",
    "    opt.n_classes = 51\n",
    "    opt.n_threads = 1\n",
    "    opt.train = False\n",
    "    opt.val = False\n",
    "    opt.inference = True\n",
    "    opt.output_topk = 5\n",
    "    opt.inference_batch_size = 1\n",
    "    opt.model_depth = 50\n",
    "    opt.model = 'resnet'\n",
    "###########    \n",
    "    if opt.root_path is not None:\n",
    "        opt.video_path = opt.root_path / opt.video_path\n",
    "        opt.annotation_path = opt.root_path / opt.annotation_path\n",
    "        opt.result_path = opt.root_path / opt.result_path\n",
    "        if opt.resume_path is not None:\n",
    "            opt.resume_path = opt.root_path / opt.resume_path\n",
    "        if opt.pretrain_path is not None:\n",
    "            opt.pretrain_path = opt.root_path / opt.pretrain_path\n",
    "\n",
    "    if opt.pretrain_path is not None:\n",
    "        opt.n_finetune_classes = opt.n_classes\n",
    "        opt.n_classes = opt.n_pretrain_classes\n",
    "\n",
    "    if opt.output_topk <= 0:\n",
    "        opt.output_topk = opt.n_classes\n",
    "\n",
    "    if opt.inference_batch_size == 0:\n",
    "        opt.inference_batch_size = opt.batch_size\n",
    "\n",
    "    opt.arch = '{}-{}'.format(opt.model, opt.model_depth)\n",
    "    opt.begin_epoch = 1\n",
    "    opt.mean, opt.std = get_mean_std(opt.value_scale, dataset=opt.mean_dataset)\n",
    "    opt.n_input_channels = 3\n",
    "    if opt.input_type == 'flow':\n",
    "        opt.n_input_channels = 2\n",
    "        opt.mean = opt.mean[:2]\n",
    "        opt.std = opt.std[:2]\n",
    "\n",
    "    if opt.distributed:\n",
    "        opt.dist_rank = int(os.environ[\"OMPI_COMM_WORLD_RANK\"])\n",
    "\n",
    "        if opt.dist_rank == 0:\n",
    "            print(opt)\n",
    "            with (opt.result_path / 'opts.json').open('w') as opt_file:\n",
    "                json.dump(vars(opt), opt_file, default=json_serial)\n",
    "    else:\n",
    "        print(opt)\n",
    "        with (opt.result_path / 'opts.json').open('w') as opt_file:\n",
    "            json.dump(vars(opt), opt_file, default=json_serial)\n",
    "\n",
    "    return opt\n",
    "\n",
    "\n",
    "%tb\n",
    "opt = get_opt()\n",
    "\n",
    "def resume_model(resume_path, arch, model):\n",
    "    print('loading checkpoint {} model'.format(resume_path))\n",
    "    checkpoint = torch.load(resume_path, map_location='cpu')\n",
    "    print(arch, \":::\", checkpoint['arch'])\n",
    "    assert arch == checkpoint['arch']\n",
    "\n",
    "    if hasattr(model, 'module'):\n",
    "        model.module.load_state_dict(checkpoint['state_dict'])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def resume_train_utils(resume_path, begin_epoch, optimizer, scheduler):\n",
    "    print('loading checkpoint {} train utils'.format(resume_path))\n",
    "    checkpoint = torch.load(resume_path, map_location='cpu')\n",
    "\n",
    "    begin_epoch = checkpoint['epoch'] + 1\n",
    "    if optimizer is not None and 'optimizer' in checkpoint:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    if scheduler is not None and 'scheduler' in checkpoint:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "\n",
    "    return begin_epoch, optimizer, scheduler\n",
    "\n",
    "def get_normalize_method(mean, std, no_mean_norm, no_std_norm):\n",
    "    if no_mean_norm:\n",
    "        if no_std_norm:\n",
    "            return Normalize([0, 0, 0], [1, 1, 1])\n",
    "        else:\n",
    "            return Normalize([0, 0, 0], std)\n",
    "    else:\n",
    "        if no_std_norm:\n",
    "            return Normalize(mean, [1, 1, 1])\n",
    "        else:\n",
    "            return Normalize(mean, std)\n",
    "\n",
    "\n",
    "def get_val_utils(opt):\n",
    "    normalize = get_normalize_method(opt.mean, opt.std, opt.no_mean_norm,\n",
    "                                     opt.no_std_norm)\n",
    "    spatial_transform = [\n",
    "        Resize(opt.sample_size),\n",
    "        CenterCrop(opt.sample_size),\n",
    "        ToTensor()\n",
    "    ]\n",
    "    if opt.input_type == 'flow':\n",
    "        spatial_transform.append(PickFirstChannels(n=2))\n",
    "    spatial_transform.extend([ScaleValue(opt.value_scale), normalize])\n",
    "    spatial_transform = Compose(spatial_transform)\n",
    "\n",
    "    temporal_transform = []\n",
    "    if opt.sample_t_stride > 1:\n",
    "        temporal_transform.append(TemporalSubsampling(opt.sample_t_stride))\n",
    "    temporal_transform.append(\n",
    "        TemporalEvenCrop(opt.sample_duration, opt.n_val_samples))\n",
    "    temporal_transform = TemporalCompose(temporal_transform)\n",
    "\n",
    "    val_data, collate_fn = get_validation_data(opt.video_path,\n",
    "                                               opt.annotation_path, opt.dataset,\n",
    "                                               opt.input_type, opt.file_type,\n",
    "                                               spatial_transform,\n",
    "                                               temporal_transform)\n",
    "    if opt.distributed:\n",
    "        val_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "            val_data, shuffle=False)\n",
    "    else:\n",
    "        val_sampler = None\n",
    "    val_loader = torch.utils.data.DataLoader(val_data,\n",
    "                                             batch_size=(opt.batch_size //\n",
    "                                                         opt.n_val_samples),\n",
    "                                             shuffle=False,\n",
    "                                             num_workers=opt.n_threads,\n",
    "                                             pin_memory=True,\n",
    "                                             sampler=val_sampler,\n",
    "                                             worker_init_fn=worker_init_fn,\n",
    "                                             collate_fn=collate_fn)\n",
    "\n",
    "    if opt.is_master_node:\n",
    "        val_logger = Logger(opt.result_path / 'val.log',\n",
    "                            ['epoch', 'loss', 'acc'])\n",
    "    else:\n",
    "        val_logger = None\n",
    "\n",
    "    return val_loader, val_logger\n",
    "\n",
    "\n",
    "def get_inference_utils(opt):\n",
    "    assert opt.inference_crop in ['center', 'nocrop']\n",
    "\n",
    "    normalize = get_normalize_method(opt.mean, opt.std, opt.no_mean_norm,\n",
    "                                     opt.no_std_norm)\n",
    "\n",
    "    spatial_transform = [Resize(opt.sample_size)]\n",
    "    if opt.inference_crop == 'center':\n",
    "        spatial_transform.append(CenterCrop(opt.sample_size))\n",
    "    spatial_transform.append(ToTensor())\n",
    "    if opt.input_type == 'flow':\n",
    "        spatial_transform.append(PickFirstChannels(n=2))\n",
    "    spatial_transform.extend([ScaleValue(opt.value_scale), normalize])\n",
    "    spatial_transform = Compose(spatial_transform)\n",
    "\n",
    "    temporal_transform = []\n",
    "    if opt.sample_t_stride > 1:\n",
    "        temporal_transform.append(TemporalSubsampling(opt.sample_t_stride))\n",
    "    temporal_transform.append(\n",
    "        SlidingWindow(opt.sample_duration, opt.inference_stride))\n",
    "    temporal_transform = TemporalCompose(temporal_transform)\n",
    "\n",
    "    inference_data, collate_fn = get_inference_data(\n",
    "        opt.video_path, opt.annotation_path, opt.dataset, opt.input_type,\n",
    "        opt.file_type, opt.inference_subset, spatial_transform,\n",
    "        temporal_transform)\n",
    "\n",
    "    inference_loader = torch.utils.data.DataLoader(\n",
    "        inference_data,\n",
    "        batch_size=opt.inference_batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=opt.n_threads,\n",
    "        pin_memory=True,\n",
    "        worker_init_fn=worker_init_fn,\n",
    "        collate_fn=collate_fn)\n",
    "\n",
    "    return inference_loader, inference_data.class_names\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(save_file_path, epoch, arch, model, optimizer, scheduler):\n",
    "    if hasattr(model, 'module'):\n",
    "        model_state_dict = model.module.state_dict()\n",
    "    else:\n",
    "        model_state_dict = model.state_dict()\n",
    "    save_states = {\n",
    "        'epoch': epoch,\n",
    "        'arch': arch,\n",
    "        'state_dict': model_state_dict,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'scheduler': scheduler.state_dict()\n",
    "    }\n",
    "    torch.save(save_states, save_file_path)\n",
    "\n",
    "\n",
    "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
    "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
    "    tmpstr = model.__class__.__name__ + ' (\\n'\n",
    "    num_layer = 0\n",
    "    for key, module in model._modules.items():\n",
    "        # if it contains layers let call it recursively to get params and weights\n",
    "        if type(module) in [\n",
    "            torch.nn.modules.container.Container,\n",
    "            torch.nn.modules.container.Sequential\n",
    "        ]:\n",
    "            modstr = torch_summarize(module)\n",
    "        else:\n",
    "            modstr = module.__repr__()\n",
    "        modstr = _addindent(modstr, 2)\n",
    "\n",
    "        params = sum([np.prod(p.size()) for p in module.parameters()])\n",
    "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
    "\n",
    "        tmpstr += '  (' + key + '): ' + modstr \n",
    "        if show_weights:\n",
    "            tmpstr += ', weights={}'.format(weights)\n",
    "        if show_parameters:\n",
    "            tmpstr +=  ', parameters={}'.format(params)\n",
    "        tmpstr += '\\n'\n",
    "        num_layer += 1\n",
    "\n",
    "    tmpstr = tmpstr + ')'\n",
    "    tmpstr = tmpstr + ' num of layer:' + str(num_layer)\n",
    "    return tmpstr\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/hmdb51_debug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_utils(opt, model_parameters):\n",
    "    assert opt.train_crop in ['random', 'corner', 'center']\n",
    "    spatial_transform = []\n",
    "    if opt.train_crop == 'random':\n",
    "        spatial_transform.append(\n",
    "            RandomResizedCrop(\n",
    "                opt.sample_size, (opt.train_crop_min_scale, 1.0),\n",
    "                (opt.train_crop_min_ratio, 1.0 / opt.train_crop_min_ratio)))\n",
    "    elif opt.train_crop == 'corner':\n",
    "        scales = [1.0]\n",
    "        scale_step = 1 / (2**(1 / 4))\n",
    "        for _ in range(1, 5):\n",
    "            scales.append(scales[-1] * scale_step)\n",
    "        spatial_transform.append(MultiScaleCornerCrop(opt.sample_size, scales))\n",
    "    elif opt.train_crop == 'center':\n",
    "        spatial_transform.append(Resize(opt.sample_size))\n",
    "        spatial_transform.append(CenterCrop(opt.sample_size))\n",
    "    normalize = get_normalize_method(opt.mean, opt.std, opt.no_mean_norm,\n",
    "                                     opt.no_std_norm)\n",
    "    if not opt.no_hflip:\n",
    "        spatial_transform.append(RandomHorizontalFlip())\n",
    "    if opt.colorjitter:\n",
    "        spatial_transform.append(ColorJitter())\n",
    "    spatial_transform.append(ToTensor())\n",
    "    if opt.input_type == 'flow':\n",
    "        spatial_transform.append(PickFirstChannels(n=2))\n",
    "    spatial_transform.append(ScaleValue(opt.value_scale))\n",
    "    spatial_transform.append(normalize)\n",
    "    spatial_transform = Compose(spatial_transform)\n",
    "\n",
    "    assert opt.train_t_crop in ['random', 'center']\n",
    "    temporal_transform = []\n",
    "    if opt.sample_t_stride > 1:\n",
    "        temporal_transform.append(TemporalSubsampling(opt.sample_t_stride))\n",
    "    if opt.train_t_crop == 'random':\n",
    "        temporal_transform.append(TemporalRandomCrop(opt.sample_duration))\n",
    "    elif opt.train_t_crop == 'center':\n",
    "        temporal_transform.append(TemporalCenterCrop(opt.sample_duration))\n",
    "    temporal_transform = TemporalCompose(temporal_transform)\n",
    "\n",
    "    # print(\"opt:\", opt)\n",
    "    train_data = get_training_data(opt.video_path, opt.annotation_path,\n",
    "                                   opt.dataset, opt.input_type, opt.file_type,\n",
    "                                   spatial_transform, temporal_transform)\n",
    "    \n",
    "    print(\"training data num: \", len(train_data))\n",
    "    if opt.distributed:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "            train_data)\n",
    "    else:\n",
    "        train_sampler = None\n",
    "    train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                               batch_size=opt.batch_size,\n",
    "                                               shuffle=(train_sampler is None),\n",
    "                                           #    num_workers=opt.n_threads,\n",
    "                                               pin_memory=True,\n",
    "                                               sampler=train_sampler,\n",
    "                                               worker_init_fn=worker_init_fn)\n",
    "\n",
    "    if opt.is_master_node:\n",
    "        train_logger = Logger(opt.result_path / 'train.log',\n",
    "                              ['epoch', 'loss', 'acc', 'lr'])\n",
    "        train_batch_logger = Logger(\n",
    "            opt.result_path / 'train_batch.log',\n",
    "            ['epoch', 'batch', 'iter', 'loss', 'acc', 'lr'])\n",
    "    else:\n",
    "        train_logger = None\n",
    "        train_batch_logger = None\n",
    "\n",
    "    if opt.nesterov:\n",
    "        dampening = 0\n",
    "    else:\n",
    "        dampening = opt.dampening\n",
    "    optimizer = SGD(model_parameters,\n",
    "                    lr=opt.learning_rate,\n",
    "                    momentum=opt.momentum,\n",
    "                    dampening=dampening,\n",
    "                    weight_decay=opt.weight_decay,\n",
    "                    nesterov=opt.nesterov)\n",
    "\n",
    "    assert opt.lr_scheduler in ['plateau', 'multistep']\n",
    "    assert not (opt.lr_scheduler == 'plateau' and opt.no_val)\n",
    "    if opt.lr_scheduler == 'plateau':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, 'min', patience=opt.plateau_patience)\n",
    "    else:\n",
    "        scheduler = lr_scheduler.MultiStepLR(optimizer,\n",
    "                                             opt.multistep_milestones)\n",
    "\n",
    "    return (train_loader, train_sampler, train_logger, train_batch_logger,\n",
    "            optimizer, scheduler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_worker(index, opt):\n",
    "    random.seed(opt.manual_seed)\n",
    "    np.random.seed(opt.manual_seed)\n",
    "    torch.manual_seed(opt.manual_seed)\n",
    "\n",
    "    if index >= 0 and opt.device.type == 'cuda':\n",
    "        opt.device = torch.device(f'cuda:{index}')\n",
    "\n",
    "    opt.is_master_node = not opt.distributed or opt.dist_rank == 0\n",
    "\n",
    "    model = generate_model(opt)\n",
    "    print('after generating model:', model.fc.in_features,':',  model.fc.out_features)\n",
    "    print('feature weights:', model.fc.weight.shape,':',  model.fc.bias.shape)\n",
    "    \n",
    "    if opt.resume_path is not None:\n",
    "        model = resume_model(opt.resume_path, opt.arch, model)\n",
    "    print('after resume model:', model.fc.in_features,':',  model.fc.out_features)\n",
    "    print('feature weights:', model.fc.weight.shape,':',  model.fc.bias.shape)\n",
    "    # summary(model, input_size=(3, 112, 112))\n",
    "#    if opt.pretrain_path:\n",
    "#        model = load_pretrained_model(model, opt.pretrain_path, opt.model,\n",
    "#                                      opt.n_finetune_classes)\n",
    "\n",
    "    print('after pretrained  model:', model.fc.in_features,':',  model.fc.out_features)\n",
    "    print('feature weights:', model.fc.weight.shape,':',  model.fc.bias.shape)\n",
    "    ######\n",
    "    # print(torch_summarize(model))\n",
    "    #########\n",
    "    \n",
    "    # parameters = model.parameters()\n",
    "    # for name, param in model.named_parameters():\n",
    "    #     if param.requires_grad:\n",
    "    #         print(name, param.data)\n",
    "#    summary(model, (3, 112, 112))\n",
    "#    return\n",
    "\n",
    "#    print('model parameters shape', parameters.shape)\n",
    "\n",
    "    (train_loader, train_sampler, train_logger, train_batch_logger,\n",
    "     optimizer, scheduler) = get_train_utils(opt, model.parameters())\n",
    "    print('after training utils')\n",
    "\n",
    "    # get some random training samples\n",
    "    dataiter = iter(train_loader)\n",
    "    print('after iter')\n",
    "    instances, labels = dataiter.next()\n",
    "    print('after next')\n",
    "    print('model size:', len(model), ' instance size:', len(instances))\n",
    "    \n",
    "    writer.add_graph(model, instances)\n",
    "    print('after add_graph')\n",
    "    writer.close()\n",
    "    print('write out model to tensorboard data')\n",
    "    return \n",
    "\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        print('input shape:', inputs.shape)\n",
    "        print('targets shape:', targets.shape)\n",
    "        outputs = model(inputs)\n",
    "        print(\"output shape\", outputs.shape)\n",
    "        model_arch = make_dot(outputs, params=dict(model.named_parameters()))\n",
    "        print(model_arch)\n",
    "        model_arch.render(\"/apollo/data/model.png\", format=\"png\")\n",
    "        # Source(model_arch).render('/apollo/data/model.png')\n",
    "        # print(\"generating /apollo/data/model.png\")\n",
    "        break\n",
    "    \n",
    "    # make_dot(yhat, params=dict(list(model.named_parameters()))).render(\"rnn_torchviz\", format=\"png\")\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "    if opt.batchnorm_sync:\n",
    "        assert opt.distributed, 'SyncBatchNorm only supports DistributedDataParallel.'\n",
    "        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "    if opt.pretrain_path:\n",
    "        model = load_pretrained_model(model, opt.pretrain_path, opt.model,\n",
    "                                      opt.n_finetune_classes)\n",
    "    if opt.resume_path is not None:\n",
    "        model = resume_model(opt.resume_path, opt.arch, model)\n",
    "    model = make_data_parallel(model, opt.distributed, opt.device)\n",
    "\n",
    "    if opt.pretrain_path:\n",
    "        parameters = get_fine_tuning_parameters(model, opt.ft_begin_module)\n",
    "    else:\n",
    "        parameters = model.parameters()\n",
    "\n",
    "    if opt.is_master_node:\n",
    "        print(model)\n",
    "\n",
    "    criterion = CrossEntropyLoss().to(opt.device)\n",
    "\n",
    "    if not opt.no_train:\n",
    "        (train_loader, train_sampler, train_logger, train_batch_logger,\n",
    "         optimizer, scheduler) = get_train_utils(opt, parameters)\n",
    "        if opt.resume_path is not None:\n",
    "            opt.begin_epoch, optimizer, scheduler = resume_train_utils(\n",
    "                opt.resume_path, opt.begin_epoch, optimizer, scheduler)\n",
    "            if opt.overwrite_milestones:\n",
    "                scheduler.milestones = opt.multistep_milestones\n",
    "    if not opt.no_val:\n",
    "        val_loader, val_logger = get_val_utils(opt)\n",
    "\n",
    "    if opt.tensorboard and opt.is_master_node:\n",
    "        from torch.utils.tensorboard import SummaryWriter\n",
    "        if opt.begin_epoch == 1:\n",
    "            tb_writer = SummaryWriter(log_dir=opt.result_path)\n",
    "        else:\n",
    "            tb_writer = SummaryWriter(log_dir=opt.result_path,\n",
    "                                      purge_step=opt.begin_epoch)\n",
    "    else:\n",
    "        tb_writer = None\n",
    "\n",
    "    prev_val_loss = None\n",
    "    for i in range(opt.begin_epoch, opt.n_epochs + 1):\n",
    "        if not opt.no_train:\n",
    "            if opt.distributed:\n",
    "                train_sampler.set_epoch(i)\n",
    "            current_lr = get_lr(optimizer)\n",
    "            train_epoch(i, train_loader, model, criterion, optimizer,\n",
    "                        opt.device, current_lr, train_logger,\n",
    "                        train_batch_logger, tb_writer, opt.distributed)\n",
    "\n",
    "            if i % opt.checkpoint == 0 and opt.is_master_node:\n",
    "                save_file_path = opt.result_path / 'save_{}.pth'.format(i)\n",
    "                save_checkpoint(save_file_path, i, opt.arch, model, optimizer,\n",
    "                                scheduler)\n",
    "\n",
    "        if not opt.no_val:\n",
    "            prev_val_loss = val_epoch(i, val_loader, model, criterion,\n",
    "                                      opt.device, val_logger, tb_writer,\n",
    "                                      opt.distributed)\n",
    "\n",
    "        if not opt.no_train and opt.lr_scheduler == 'multistep':\n",
    "            scheduler.step()\n",
    "        elif not opt.no_train and opt.lr_scheduler == 'plateau':\n",
    "            scheduler.step(prev_val_loss)\n",
    "\n",
    "    if opt.inference:\n",
    "        inference_loader, inference_class_names = get_inference_utils(opt)\n",
    "        inference_result_path = opt.result_path / '{}.json'.format(\n",
    "            opt.inference_subset)\n",
    "\n",
    "        inference.inference(inference_loader, model, inference_result_path,\n",
    "                            inference_class_names, opt.inference_no_average,\n",
    "                            opt.output_topk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after generating model: 2048 : 51\n",
      "feature weights: torch.Size([51, 2048]) : torch.Size([51])\n",
      "loading checkpoint datasets/hmdb51/results/save_200.pth model\n",
      "resnet-50 ::: resnet-50\n",
      "after resume model: 2048 : 51\n",
      "feature weights: torch.Size([51, 2048]) : torch.Size([51])\n",
      "after pretrained  model: 2048 : 51\n",
      "feature weights: torch.Size([51, 2048]) : torch.Size([51])\n",
      "dataset name: hmdb51\n",
      "video_path: datasets/hmdb51/image\n",
      "annotation_path: datasets/hmdb51/hmdb51_total.json\n",
      "annotation_path: datasets/hmdb51/hmdb51_total.json\n",
      "annotation data num: 2\n",
      "num video: 4057\n",
      "dataset loading [0/4057]\n",
      "dataset loading [811/4057]\n",
      "dataset loading [1622/4057]\n",
      "dataset loading [2433/4057]\n",
      "dataset loading [3244/4057]\n",
      "dataset loading [4055/4057]\n",
      "training data num:  4057\n",
      "after training utils\n",
      "after iter\n",
      "after next\n",
      "after add_graph\n",
      "write out model to tensorboard data\n"
     ]
    }
   ],
   "source": [
    "opt.device = torch.device('cpu' if opt.no_cuda else 'cuda')\n",
    "if not opt.no_cuda:\n",
    "    cudnn.benchmark = True\n",
    "if opt.accimage:\n",
    "    torchvision.set_image_backend('accimage')\n",
    "\n",
    "opt.ngpus_per_node = torch.cuda.device_count()\n",
    "main_worker(-1, opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
